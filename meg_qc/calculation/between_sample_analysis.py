"""Utilities for comparing MEGqc metrics across multiple samples.

This script expects the TSV files generated by the MEGqc pipeline for each
sample and produces a set of violin plots and a linear regression table
comparing the samples.

Example
-------
Assuming you have the metrics exported for two datasets, run::

    python -m meg_qc.calculation.between_sample_analysis \
        --tsv sample1/group_metrics.tsv sample2/group_metrics.tsv \
        --names sample1 sample2 \
        --output-dir results

All figures and the regression table will be stored in ``results``.
"""
import argparse
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from scipy import stats
import statsmodels.api as sm
from sklearn.feature_selection import mutual_info_regression
import seaborn as sns

LABEL_MAP = {
    "GQI": "GQI",
    "GQI_std_pct": "STD noise",
    "GQI_ptp_pct": "PtP noise",
    "GQI_ecg_pct": "ECG noise",
    "GQI_eog_pct": "EOG noise",
    "GQI_muscle_pct": "Muscle noise",
    "GQI_psd_noise_pct": "PSD noise",
    "GQI_penalty_ch": "Variability penalty",
    "GQI_penalty_corr": "Correlational penalty",
    "GQI_penalty_mus": "Muscle penalty",
    "GQI_penalty_psd": "PSD penalty",
}


def _get_star(p):
    """Return asterisks representing the p-value significance."""
    if p < 0.001:
        return "***"
    if p < 0.01:
        return "**"
    if p < 0.05:
        return "*"
    return ""


def _load_tables(paths):
    """Load TSV tables into pandas DataFrames."""
    tables = []
    for p in paths:
        df = pd.read_csv(p, sep="\t")
        tables.append(df)
    return tables


def _make_violin(data, names, title, ylabel, out_png):
    """Create violin plot comparing samples."""
    violin_data = [d.dropna() for d in data]
    palette = cm.get_cmap("tab10", len(violin_data))
    plt.figure(figsize=(10, 6))
    parts = plt.violinplot(violin_data, showmeans=True, showextrema=True,
                            showmedians=False, widths=0.8)
    for i, pc in enumerate(parts["bodies"]):
        pc.set_facecolor(palette(i))
        pc.set_edgecolor("black")
        pc.set_alpha(0.5)
    parts["cmeans"].set_linewidth(2)
    parts["cmeans"].set_color("black")
    parts["cbars"].set_color("black")
    for i, y in enumerate(violin_data, start=1):
        x = np.random.normal(i, 0.05, size=len(y))
        plt.scatter(x, y, s=20, alpha=0.4, edgecolor="black", linewidth=0.5,
                    facecolor=palette(i - 1))
    plt.xticks(range(1, len(names) + 1), names, rotation=0, ha="center", fontsize=10)
    plt.ylabel(ylabel)
    plt.title(title)
    plt.tight_layout()
    plt.savefig(out_png, dpi=300)
    plt.close()


def _cumulative_plot(tables, metrics, names, out_png, out_tsv=None, compute_ttest=True):
    """Create a cumulative violin plot of several metrics for each sample.

    Parameters
    ----------
    tables : list of pandas.DataFrame
        Tables with metrics for each sample.
    metrics : list of str
        Metrics to include in the plot.
    names : list of str
        Sample names.
    out_png : str
        Path where the figure will be saved.
    out_tsv : str or None
        If provided and ``compute_ttest`` is True, pairwise t-test results
        are written to this file.
    compute_ttest : bool, optional
        Whether to compute pairwise t-tests and annotate the plot.
    """
    n_samples = len(names)
    fig, ax = plt.subplots(figsize=(12, 6))
    palette = cm.get_cmap("tab10", len(metrics))

    positions = []
    labels = []
    results = []
    for j, metric in enumerate(metrics):
        metric_values = []
        for i, name in enumerate(names):
            data = tables[i][metric].dropna()
            pos = j * n_samples + i + 1
            parts = ax.violinplot(
                [data],
                positions=[pos],
                showmeans=True,
                showextrema=True,
                showmedians=False,
                widths=0.8,
            )
            color = palette(j)
            for pc in parts["bodies"]:
                pc.set_facecolor(color)
                pc.set_edgecolor("black")
                pc.set_alpha(0.5)
            parts["cmeans"].set_linewidth(2)
            parts["cmeans"].set_color("black")
            parts["cbars"].set_color("black")
            x = np.random.normal(pos, 0.05, size=len(data))
            ax.scatter(
                x,
                data,
                s=20,
                alpha=0.4,
                edgecolor="black",
                linewidth=0.5,
                facecolor=color,
            )
            metric_values.append(data)
            positions.append(pos)
            labels.append(name)

        if compute_ttest:
            # add significance annotations
            y_range = ax.get_ylim()
            y_offset = (y_range[1] - y_range[0]) * 0.05
            offset_count = 0
            for a in range(n_samples):
                for b in range(a + 1, n_samples):
                    stat, p = stats.ttest_ind(
                        metric_values[a],
                        metric_values[b],
                        equal_var=False,
                    )
                    star = _get_star(p)
                    results.append(
                        {
                            "metric": metric,
                            "sample1": names[a],
                            "sample2": names[b],
                            "t_stat": stat,
                            "p": p,
                            "asterisk": star,
                        }
                    )
                    if not star:
                        continue
                    x1 = j * n_samples + a + 1
                    x2 = j * n_samples + b + 1
                    y = max(metric_values[a].max(), metric_values[b].max()) + (
                        offset_count + 1
                    ) * y_offset
                    ax.plot(
                        [x1, x1, x2, x2],
                        [y, y + y_offset / 2, y + y_offset / 2, y],
                        color="black",
                    )
                    ax.text((x1 + x2) / 2, y + y_offset / 2, star, ha="center", va="bottom")
                    offset_count += 1

    ax.set_xticks(positions)
    ax.set_xticklabels(labels, rotation=0, ha="center", fontsize=9)
    ax.set_ylabel("Percentage of Quality and Noisy Channels")
    ax.set_title("Metrics across samples")

    secax = ax.secondary_xaxis(
        "bottom",
        functions=(lambda x: x, lambda x: x),
    )
    centers = [j * n_samples + (n_samples + 1) / 2 for j in range(len(metrics))]
    secax.set_xticks(centers)
    secax.set_xticklabels([LABEL_MAP.get(m, m) for m in metrics], fontsize=10, fontweight="bold")
    secax.tick_params(pad=20)

    fig.tight_layout()
    fig.savefig(out_png, dpi=300)
    if out_tsv is not None and compute_ttest:
        pd.DataFrame(results).to_csv(out_tsv, sep="\t", index=False)
    plt.close(fig)


def _perform_regression(df, metrics, out_tsv):
    """Run linear regression and save results."""
    X = df[metrics].copy()
    # add all pairwise interactions
    for i, m1 in enumerate(metrics):
        for m2 in metrics[i + 1:]:
            X[f"{m1}:{m2}"] = df[m1] * df[m2]
    X = sm.add_constant(X)
    model = sm.OLS(df["GQI"], X, missing="drop").fit()
    res_df = pd.DataFrame({
        "variable": model.params.index,
        "coef": model.params.values,
        "std_err": model.bse.values,
        "t": model.tvalues.values,
        "p": model.pvalues.values,
    })
    res_df["asterisk"] = res_df["p"].apply(_get_star)
    res_df.to_csv(out_tsv, sep="\t", index=False)
    return model, res_df


def _mutual_information(df, metrics, out_png, out_tsv):
    """Compute pairwise mutual information between metrics.

    Parameters
    ----------
    df : pandas.DataFrame
        Data frame containing the metrics.
    metrics : list of str
        Metrics to include in the analysis.
    out_png : str
        Path to save the heatmap figure.
    out_tsv : str
        Path to save the mutual information matrix as TSV.
    """
    data = df[metrics].dropna()
    n_neighbors = max(1, min(3, len(data) - 1))
    mi_matrix = pd.DataFrame(index=metrics, columns=metrics, dtype=float)
    for m1 in metrics:
        for m2 in metrics:
            if m1 == m2:
                mi = np.nan
            else:
                mi = mutual_info_regression(
                    data[[m1]],
                    data[m2],
                    discrete_features=False,
                    n_neighbors=n_neighbors,
                )[0]
            mi_matrix.loc[m1, m2] = mi

    mi_matrix.to_csv(out_tsv, sep="\t")

    plt.figure(figsize=(8, 6))
    sns.heatmap(mi_matrix.astype(float), annot=True, fmt=".2f", cmap="viridis")
    plt.title("Mutual Information between noise metrics")
    plt.tight_layout()
    plt.savefig(out_png, dpi=300)
    plt.close()




def main():
    parser = argparse.ArgumentParser(description="Between sample analysis")
    parser.add_argument("--tsv", nargs="+", required=True,
                        help="Paths to group metrics TSV files")
    parser.add_argument("--names", nargs="+", required=True,
                        help="Sample names corresponding to TSV files")
    parser.add_argument("--output-dir", required=True, help="Directory for outputs")
    parser.add_argument("--ttest", action="store_true", help="Compute pairwise t-tests for the cumulative plot")
    args = parser.parse_args()

    if len(args.tsv) != len(args.names):
        raise ValueError("Number of TSV files must match number of names")

    os.makedirs(args.output_dir, exist_ok=True)
    cumulative_dir = os.path.join(args.output_dir, "cummlative_violin_plot")
    separated_dir = os.path.join(args.output_dir, "separated_violin_plot")
    regression_dir = os.path.join(args.output_dir, "regression")
    mi_dir = os.path.join(args.output_dir, "mutual_information")
    os.makedirs(cumulative_dir, exist_ok=True)
    os.makedirs(separated_dir, exist_ok=True)
    os.makedirs(regression_dir, exist_ok=True)
    os.makedirs(mi_dir, exist_ok=True)

    tables = _load_tables(args.tsv)
    metrics = [
        "GQI_std_pct",
        "GQI_ptp_pct",
        "GQI_ecg_pct",
        "GQI_eog_pct",
        "GQI_muscle_pct",
        "GQI_psd_noise_pct",
    ]

    # Violin plot for GQI
    gqi_data = [tbl["GQI"] for tbl in tables]
    _make_violin(
        gqi_data,
        args.names,
        "Global Quality Index",
        LABEL_MAP["GQI"],
        os.path.join(separated_dir, "GQI_violin.png"),
    )

    # Metric specific violin plots
    for m in metrics:
        metric_data = [t[m] for t in tables if m in t.columns]
        if not metric_data:
            continue
        _make_violin(
            metric_data,
            args.names,
            LABEL_MAP.get(m, m),
            LABEL_MAP.get(m, m),
            os.path.join(separated_dir, f"{m}_violin.png"),
        )

    _cumulative_plot(
        tables,
        ["GQI", *metrics],
        args.names,
        os.path.join(cumulative_dir, "cumulative_metrics.png"),
        os.path.join(cumulative_dir, "t_test_results.tsv") if args.ttest else None,
        compute_ttest=args.ttest,
    )

    # Combine all data for regression
    df_all = []
    for name, tbl in zip(args.names, tables):
        temp = tbl.copy()
        temp["sample"] = name
        df_all.append(temp)
    df_all = pd.concat(df_all, ignore_index=True)

    reg_model, res_df = _perform_regression(
        df_all, metrics, os.path.join(regression_dir, "linear_regression_results.tsv")
    )

    # Mutual information per sample
    for name, tbl in zip(args.names, tables):
        _mutual_information(
            tbl,
            metrics,
            os.path.join(mi_dir, f"{name}_mutual_information.png"),
            os.path.join(mi_dir, f"{name}_mutual_information.tsv"),
        )

    # Mutual information across all samples
    _mutual_information(
        df_all,
        metrics,
        os.path.join(mi_dir, "mutual_information.png"),
        os.path.join(mi_dir, "mutual_information.tsv"),
    )


if __name__ == "__main__":
    main()
