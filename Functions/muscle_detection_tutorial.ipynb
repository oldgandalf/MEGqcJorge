{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "mne.viz.set_browser_backend('matplotlib')\n",
        "#%matplotlib qt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "# Annotate muscle artifacts\n",
        "\n",
        "Muscle contractions produce high frequency activity that can mask brain signal\n",
        "of interest. Muscle artifacts can be produced when clenching the jaw,\n",
        "swallowing, or twitching a cranial muscle. Muscle artifacts are most\n",
        "noticeable in the range of 110-140 Hz.\n",
        "\n",
        "This example uses :func:`~mne.preprocessing.annotate_muscle_zscore` to annotate\n",
        "segments where muscle activity is likely present. This is done by band-pass\n",
        "filtering the data in the 110-140 Hz range. Then, the envelope is taken using\n",
        "the hilbert analytical signal to only consider the absolute amplitude and not\n",
        "the phase of the high frequency signal. The envelope is z-scored and summed\n",
        "across channels and divided by the square root of the number of channels.\n",
        "Because muscle artifacts last several hundred milliseconds, a low-pass filter\n",
        "is applied on the averaged z-scores at 4 Hz, to remove transient peaks.\n",
        "Segments above a set threshold are annotated as ``BAD_muscle``. In addition,\n",
        "the ``min_length_good`` parameter determines the cutoff for whether short\n",
        "spans of \"good data\" in between muscle artifacts are included in the\n",
        "surrounding \"BAD\" annotation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Adonay Nunes <adonay.s.nunes@gmail.com>\n",
        "#          Luke Bloy <luke.bloy@gmail.com>\n",
        "# License: BSD-3-Clause"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mne.datasets.brainstorm import bst_auditory\n",
        "from mne.io import read_raw_ctf\n",
        "from mne.preprocessing import annotate_muscle_zscore\n",
        "\n",
        "\n",
        "# Load data\n",
        "data_path = bst_auditory.data_path()\n",
        "raw_fname = data_path / 'MEG' / 'bst_auditory' / 'S01_AEF_20131218_01.ds'\n",
        "\n",
        "raw = read_raw_ctf(raw_fname, preload=False)\n",
        "\n",
        "raw.crop(130, 160).load_data()  # just use a fraction of data for speed here\n",
        "raw.resample(300, npad=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import mne\n",
        "from mne.preprocessing import annotate_muscle_zscore\n",
        "\n",
        "\n",
        "data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003483/sub-009/ses-1/meg/sub-009_ses-1_task-deduction_run-1_meg.fif'\n",
        "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003352/sub-1/ses-01/meg/sub-1_ses-01_task-ColorSpirals_run-00_meg.fif'\n",
        "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003352/sub-4/ses-02/meg/sub-4_ses-02_task-ColorSpirals_run-01_meg.fif'\n",
        "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003392/sub-01/meg/sub-01_task-localizer_meg.fif'\n",
        "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003645/sub-002/meg/sub-002_task-FacePerception_run-1_meg.fif'\n",
        "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003694/sub-02/meg/sub-02_task-MEM_run-01_meg.fif'\n",
        "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004107/sub-mind002/ses-01/meg/sub-mind002_ses-01_task-auditory_meg.fif'\n",
        "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds004276/sub-002/meg/sub-002_task-words_meg.fif'\n",
        "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003703/sub-a68d5xp5/meg/sub-a68d5xp5_task-listeningToSpeech_run-01_meg.fif'\n",
        "#data_file = '/Volumes/M2_DATA/MEG_QC_stuff/data/from openneuro/ds003682/sub-001/ses-01/meg/sub-001_ses-01_task-AversiveLearningReplay_run-01_meg.fif'\n",
        "\n",
        "\n",
        "raw = mne.io.read_raw_fif(data_file, on_split_missing='ignore')\n",
        "\n",
        "#And resample it!\n",
        "\n",
        "#crop the data to calculate faster\n",
        "# raw_cropped = raw.copy()\n",
        "# raw_cropped.crop(tmin=1000, tmax=None) \n",
        "\n",
        "raw.crop(tmin=200, tmax=None).load_data() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notch filter the data:\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>If line noise is present, you should perform notch-filtering *before*\n",
        "    detecting muscle artifacts. See `tut-section-line-noise` for an\n",
        "    example.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.notch_filter([60, 120])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The threshold is data dependent, check the optimal threshold by plotting\n",
        "# ``scores_muscle``.\n",
        "threshold_muscle = 5  # z-score\n",
        "# Choose one channel type, if there are axial gradiometers and magnetometers,\n",
        "# select magnetometers as they are more sensitive to muscle activity.\n",
        "annot_muscle, scores_muscle = annotate_muscle_zscore(\n",
        "    raw, ch_type=\"mag\", threshold=threshold_muscle, min_length_good=0.2,\n",
        "    filter_freq=[110, 140])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot muscle z-scores across recording\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(raw.times, scores_muscle)\n",
        "ax.axhline(y=threshold_muscle, color='r')\n",
        "ax.set(xlabel='time, (s)', ylabel='zscore', title='Muscle activity')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the annotations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "order = np.arange(144, 164)\n",
        "raw.set_annotations(annot_muscle)\n",
        "raw.plot(start=5, duration=20, order=order)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mpld3\n",
        "\n",
        "fig2=raw.plot(start=5, duration=20, order=order)\n",
        "mpld3.save_html(fig2, 'should be interactive but not.html')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!jupyter nbconvert muscle_detection_tutorial.ipynb --to python"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('mne_new')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:52) \n[Clang 13.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d401ab1bf6dd7bb97662b0feb1321a641d60d04842bfa92b47f7871360972b5d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
